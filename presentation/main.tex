\documentclass[aspectratio=169]{beamer}
\usetheme{Boadilla}
\setbeamertemplate{navigation symbols}{}
\usepackage{graphicx} % Required for inserting images
\graphicspath{{./figures}}
\usepackage[autostyle=true]{csquotes}
\usepackage[T2A]{fontenc}
\usepackage[english, russian]{babel}
\usepackage{booktabs}
\usepackage{multirow}

\title{Interactive Speaker Recognition}
\subtitle{Применение обучения с подкреплением для решения задачи распознавания
          диктора}
\author[В.С.~Головин]{Вячеслав Головин \texorpdfstring{\newline}{, }
    {\small Евгений Шуранов (руководитель)}}
\institute[ВШЭ]{Huawei CBG AI и ФКН ВШЭ СПб}
\date{16.05.2023}

\newcommand{\guesser}{\texttt{Guesser}}
\newcommand{\enquirer}{\texttt{Enquirer}}
\newcommand{\imgscale}{0.8}

\begin{document}

\frame{\titlepage}

\begin{frame}{}
    \textbf{Задача:} повышение точности систем верификации / идентификации
    диктора. Такая система может, например, быть использована для подтверждение
    личности на мобильных устройствах.\vspace{1em}

    \textbf{Требования к системе:}
    \begin{itemize}
        \item короткие запросы (не раздражаем пользователя),
        \item разнообразные запросы (не боимся спуфинга),
        \item высокая точность (без комментариев).
    \end{itemize}\vspace{1em}

    \textbf{Предлагаемое решение:} использование RL-агента для выбора
    запрашиваемых слов.\vspace{1em}

    \textbf{Новизна дипломной работы:}
    \begin{itemize}
        \item переход от идентификации к верификации,
        \item более гибкая система для выбора слов.
    \end{itemize}
\end{frame}

\begin{frame}{Interactive Speaker Recognition}
    Метод был предложен в статье \textit{A Machine of Few Words --- Interactive
    Speaker Recognition with Reinforcement Learning}, Mathieu Seurin et al.,
    INTERSPEECH 2020, arXiv:2008.03127v1.\vspace{1em}

    \begin{columns}
    
    \column{0.6\textwidth}
    \begin{figure}[bht]
        \includegraphics[width=.9\textwidth]{isr_game_large.png}
        % \caption{Общая схема подхода ISR}
    \end{figure}

    \column{0.4\textwidth}
    Важные особенности:
    \begin{enumerate}
        \item Рассматривается только задача идентификации.
        \item Набор слов строго фиксирован.
        \item Разные нейронные сети для двух задач SR Module --- запроса слов
        (\enquirer) и идентификации диктора (\guesser).
    \end{enumerate}
    \end{columns}
\end{frame}

\begin{frame}{Блок Guesser}
\framesubtitle{Архитектура}
    \begin{columns}
 
    \column{0.6\textwidth}
    \begin{figure}[bht]
    \includegraphics[width=.8\textwidth]{guesser.png}
    % \caption{Архитектура блока Guesser}
    \end{figure}

    \column{0.4\textwidth}
    Входные данные:
    \begin{itemize}
        \item эмбеддинги дикторов\\
            $G = [g_1; g_2; \ldots g_K]$
        \item эмбеддинги слов\\
            $X = [x_1; x_2; \ldots x_T]$
    \end{itemize}
    Выходные данные:
    \begin{itemize}
        \item вероятности
            $\{P(g_i = g^*) \;|\; i=1..K\}$
    \end{itemize}
    \end{columns}

    \begin{block}{Обозначения}
    \begin{tabular}{l l}
        $K$ & количество гостей / дикторов\\
        $T$ & количество запрашиваемых слов
    \end{tabular}
    \end{block}
\end{frame}

\begin{frame}[fragile]{Блок Guesser}
\framesubtitle{Псевдокод 1 итерации обучения}
\input{guesser_forward.tex}
    \begin{block}{Обозначения}
    \begin{tabular}{l l}
        $K$ & количество гостей / дикторов\\
        $T$ & количество запрашиваемых слов\\
        $V$ & размер словаря --- число доступных для запроса слов
    \end{tabular}
    \end{block}
\end{frame}

\begin{frame}{Блок Enquirer}
\framesubtitle{Архитектура}
    \begin{columns}
    
    \column{0.6\textwidth}
    \begin{figure}[bht]
    \includegraphics[width=.9\textwidth]{enquirer.png}
    % \caption{Архитектура блока Enquirer}
    \end{figure}

    \column{0.4\textwidth}
    Входные данные:
    \begin{itemize}
        \item среднее эмб. дикторов\\
            $\hat{g} = \frac{1}{K}{\sum_{i=1}^{K}{g_k}}$
        \item эмбеддинги слов\\
            $X = [x_1; x_2; \ldots; x_t]$
    \end{itemize}
    Выходные данные:
    \begin{itemize}
        \item вероятность выбрать каждое из слов
    \end{itemize}

    \end{columns}

    \begin{block}{Обозначения}
    \begin{tabular}{l l}
        $K$ & количество гостей / дикторов\\
        $T$ & количество запрашиваемых слов\\
        $t$ & количество запрошенных слов, $0 \leq t \leq T$
    \end{tabular}
    \end{block}
\end{frame}

\begin{frame}[fragile]{Блок Enquirer}
\framesubtitle{Псевдокод 1 эпизода ISR-игры}
\footnotesize
\input{enquirer_forward.tex}
\end{frame}

\begin{frame}{Входные данные}
    Для обучения использовался датасет \textbf{TIMIT}:
    \begin{itemize}
        \item 630 дикторов из США, 8 акцентов;
        \item каждый диктор произносит 10 предложений: 8 уникальных и 2 общих.
    \end{itemize}

    В качестве эмбеддингов использовались \textbf{x-vectors}, полученные с помощью нейронной сети, обученной на аугментированных датасетах для распознавания диктора \textit{Switchboard}, \textit{Mixer 6} и \textit{NIST}.
    \begin{itemize}
        \item Эмбеддинги дикторов $g$ получались с помощью усреднения
        эмбеддингов 8 уникальных предложений.
        \item Эмбеддинги слов $x$ извлекались с помощью 2 общих предложений,
        т.е. сначала вырезались записи одиночных слов, которые затем
        пропускались через нейронную сеть.
    \end{itemize}
\end{frame}

\begin{frame}{Результаты из статьи}
    \framesubtitle{$K = 5$ дикторов и $T = 3$ слова}
    \begin{columns}
        \centering
        \column{.5\textwidth}
        \includegraphics[scale=0.5]{isr_training.png}
        \column{.5\textwidth}
        \includegraphics[scale=0.5]{isr_word_sweep.png}
    \end{columns}\vspace*{1em}

    RL-агент при выборе запрашиваемых слов учитывает контекст --- он опережает
    не только случайного агента, но и эвристического, выбирающего из
    подмножества ``лучших'' слов.\vspace*{1em}

    Преимущество RL-агента невелико и проявляется только при небольшом числе
    запрашиваемых слов.
\end{frame}

\begin{frame}[t]{Обучение и тестирование \guesser{}}
    \framesubtitle{$K = 5$ дикторов  и $T = 3$ слова при обучении}
    \begin{columns}
        \centering
        \column{.5\textwidth}
        \includegraphics[scale=\imgscale]{../plots/word_sweep.pdf}
        \column{.5\textwidth}
        \includegraphics[scale=\imgscale]{../plots/guest_sweep.pdf}
    \end{columns}\vspace*{1em}

    Вероятно, главная причина расхождения результатов --- увеличение размерности
    эмбеддингов (512 вместо 128 в статье). Неизвестно, как и зачем в статье
    производилось понижение размерности.
\end{frame}

\begin{frame}[t]{Обучение и тестирование \enquirer{}}
    \framesubtitle{$K = 5$ дикторов  и $T = 3$ слова при обучении}
    \begin{columns}
        \centering
        \column{.5\textwidth}
        \includegraphics[scale=\imgscale]{../plots/word_sweep_enq.pdf}
        \column{.5\textwidth}
        \includegraphics[scale=\imgscale]{../plots/guest_sweep_enq.pdf}
    \end{columns}\vspace*{1em}
    Для обучения использовалась \textbf{PPO}. Выбор слова при обучении и
    тестировании проводился по-разному:
    \begin{itemize}
        \item \texttt{train} --- сэмплирование из распределения,
        \item \texttt{test} --- $\arg \max$ по не использованным ранее словам.
    \end{itemize}
\end{frame}

\begin{frame}{Эвристический агент}
    \framesubtitle{Алгоритм работы}
    \begin{columns}[b]
        \column{.3\textwidth}
        \includegraphics[height=.8\textheight]{../plots/word_scores.pdf}
        \column{.7\textwidth}
        \begin{enumerate}
            \item Рассчитываем точность на валидационной выборке.
            \item Сэмплируем из слов с самой высокой точностью.
        \end{enumerate}
        \begin{center}
            \includegraphics[scale=\imgscale]{../plots/heuristic.pdf}
        \end{center}
    \end{columns}
\end{frame}

\begin{frame}[t]{Эвристический агент}
    \framesubtitle{Сравнение с \enquirer}
    \begin{columns}
        \centering
        \column{.5\textwidth}
        \includegraphics[scale=\imgscale]{../plots/word_sweep_heuristic.pdf}
        \column{.5\textwidth}
        \includegraphics[scale=\imgscale]{../plots/guest_sweep_heuristic.pdf}
    \end{columns}\vspace*{1em}
    \begin{itemize}
        \item Обучение в режиме с $K = 5$ дикторами и $T = 3$ запрашиваемыми
              словами.
        \item При $T = 1$ \enquirer{} работает плохо.  Можно обучать на 1 слове,
              но такая система плохо работает в других режимах.
    \end{itemize}
\end{frame}

\begin{frame}{Верификация}
    \framesubtitle{Как преобразовать \guesser}

    \begin{columns}
        \column{0.6\textwidth}
        \begin{figure}[bht]
        \includegraphics[width=.8\textwidth]{guesser.png}
        \end{figure}

        \column{0.4\textwidth}
        \begin{itemize}
            \item только 1 диктор $\implies$ $\hat{g} = g_0$
            \item \texttt{softmax} $\rightarrow$ \texttt{sigmoid} 
            \item при $T = 3$ точность 0.91\\($\sim$ как в классификации с
                  $K = 7$ гостями)
            \item \texttt{MLP} $\rightarrow$ \texttt{CosineSimilarity} тоже
                  работает, но хуже
        \end{itemize}
    \end{columns}
\end{frame}

\begin{frame}{Верификация}
    \framesubtitle{Как преобразовать \enquirer}
    \begin{columns}
        \column{0.6\textwidth}
        \begin{figure}[bht]
        \includegraphics[width=.9\textwidth]{enquirer.png}
        \end{figure}

        \column{0.4\textwidth}
        \begin{itemize}
            \item только 1 диктор $\implies$ $\hat{g} = g_0$
            \item архитектуру менять не нужно
            \item можно взять веса для идентификации
        \end{itemize}\vspace{1em}

        Результаты ($T = 3$ слова):
        \begin{center}
            \begin{tabular}{c c}
                \toprule
                Выбор слов & Точность\\
                \midrule
                случайный & 0.895\\
                \enquirer{} & 0.933\\
                эвристика & 0.917\\
                \bottomrule
            \end{tabular}
        \end{center}
    \end{columns}
\end{frame}

\begin{frame}{Обучение в более тяжелом режиме}
    \only<2>{
        \begin{table}[htb]
            \begin{tabular}{c c c}
                \toprule
                Выбор слов & Режим обучения & Точность\\
                \midrule
                случайный & \multirow{3}{4em}{$K = 5$\newline$T = 3$} & 0.937 \\
                \enquirer{} & & 0.982\\
                эвристика & & 0.984\\
                \midrule
                случайный & \multirow{3}{4em}{$K = 20$\\$T = 2$} & 0.951 \\
                \enquirer{} & & 0.989\\
                эвристика & & 0.988\\
                \bottomrule
            \end{tabular}
            \caption{Точность идентификации, $K = 5$ дикторов, $T = 3$
                     запрашиваемых слова}
        \end{table}
    }
    \only<1>{
        \begin{table}[htb]
            \begin{tabular}{c c c}
                \toprule
                Выбор слов & Режим обучения & Точность\\
                \midrule
                случайный & \multirow{3}{4em}{$T = 3$} & 0.895 \\
                \enquirer{} & & 0.933\\
                эвристика & & 0.917\\
                \midrule
                случайный & \multirow{3}{4em}{$T = 2$} & 0.913 \\
                \enquirer{} & & 0.947\\
                эвристика & & 0.945\\
                \bottomrule
            \end{tabular}
            \caption{Точность верификации, $T = 3$ запрашиваемых слова}
        \end{table}
    }
\end{frame}

\begin{frame}{\texttt{CodebookEnquirer}}
    \framesubtitle{Мотивация и принцип работы}
    Очевидный недостаток архитектуры \enquirer{} --- строго фиксированный набор
    слов, при любом его изменении нужно обучать заново или делать fine-tuning.
    \vspace{1em}

    \begin{columns}

    \column{0.6\textwidth}
    \begin{figure}[bht]
    \includegraphics[width=.8\textwidth]{guesser.png}
    \end{figure}

    \column{0.4\textwidth}
    Предлагаемые изменения:
    \begin{itemize}
        \item MLP возвращает эмбеддинг слова, а не вероятности;
        \item добавляется \texttt{Codebook} --- набор (фиксированных)
            эмбеддингов слов;
        \item вероятность выбрать слово из \texttt{Codebook} обратно
            пропорциональна расстоянию между эмбеддингами.
    \end{itemize}

    \end{columns}
\end{frame}

\begin{frame}{\texttt{CodebookEnquirer}}
    \framesubtitle{Результаты}
        \begin{table}[htb]
            \begin{tabular}{c c c}
                \toprule
                Выбор слов & Режим обучения & Точность\\
                \midrule
                случайный & \multirow{4}{4em}{$K = 5$\\$T = 3$} & 0.937 \\
                \enquirer{} & & 0.982 \\
                \texttt{CodebookEnquirer} & & 0.964\\
                \texttt{CodebookEnquirer} (половина слов) & & 0.970\\
                \midrule
                случайный & \multirow{4}{4em}{$K = 20$\\$T = 2$} & 0.951 \\
                \enquirer{} & & 0.989\\
                \texttt{CodebookEnquirer} & & 0.990\\
                \texttt{CodebookEnquirer} (половина слов) & & 0.980\\
                \bottomrule
            \end{tabular}
            \caption{Точность идентификации, $K = 5$ дикторов, $T = 3$
                     запрашиваемых слова}
        \end{table}
\end{frame}

\begin{frame}{Добавление шума}
    \begin{itemize}
        \item 6 различных вариантов шума из датасета MUSAN для каждого слова:
        \texttt{rain}, \texttt{car}, \texttt{crowd}, \texttt{typing},
        \texttt{hum}, \texttt{white} --- а также исходная чистая аудиозапись.
        \item SNR 3~dB.
        \item Тип шума не меняется в течение эпизода.
    \end{itemize}

    \begin{table}[htb]
        \begin{tabular}{c c c}
            \toprule
            Модель & Идентификация & Верификация\\
            \midrule
            \guesser{} & 0.887 & 0.895\\
            \guesser{} + \enquirer{} & 0.946 & 0.934\\
            \guesser{} + эвристика (3 лучших) & 0.957 & 0.938\\
            \bottomrule
        \end{tabular}
        \caption{Точность идентификации и верификации в стандартных режимах
        ($T = 3$ слова, $K = 5$ гостей при идентификации)}
    \end{table}
\end{frame}

\end{document}
