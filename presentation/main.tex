\documentclass{beamer}
\usetheme{Boadilla}
\setbeamertemplate{navigation symbols}{}
\usepackage{graphicx} % Required for inserting images
\graphicspath{{./figures}}
\usepackage[autostyle=true]{csquotes}
\usepackage[T2A]{fontenc}
%\usepackage{hyphenat}
\usepackage[english, russian]{babel}

\title{Interactive Speaker Recognition}
\subtitle{Применение обучения с подкреплением для решения задачи распознавания
          диктора}
\author[В.С.~Головин]{Вячеслав Головин \texorpdfstring{\newline}{, }
    {\small Александр Самарин (руководитель)}}
\institute[ВШЭ]{Huawei CBG AI и ФКН ВШЭ СПб}
\date{11.04.2023}

\begin{document}

\frame{\titlepage}

\begin{frame}{Мотивация}
    \textbf{Задача:} повышение точности систем верификации / идентификации
    диктора без использования длинных или строго фиксированных
    аудиозаписей.\vspace{1em}

    \textbf{Предлагаемое решение:} использование агента, выбирающего в
    зависимости от контекста, какое слово должен произнести диктор. Для обучения
    агента предлагается использовать reinforcement learning (RL).
\end{frame}

\begin{frame}{Interactive Speaker Recognition}
    Метод был предложен в статье \textit{A Machine of Few Words --- Interactive
    Speaker Recognition with Reinforcement Learning}, Mathieu Seurin et al.,
    INTERSPEECH 2020, arXiv:2008.03127v1.\vspace{1em}

    \begin{columns}
    
    \column{0.6\textwidth}
    \begin{figure}[bht]
        \includegraphics[width=.9\textwidth]{isr_game_large.png}
        % \caption{Общая схема подхода ISR}
    \end{figure}

    \column{0.4\textwidth}
    \textbf{SR Module} состоит из 2 частей:
    \begin{itemize}
        \item \textbf{Guesser} выполняет идентификацию, обучается с помощью
              supervised learning.
        \item \textbf{Enquirer} запрашивает слова, обучается с помощью
              reinforcement learning.
    \end{itemize}
    
    \end{columns}
\end{frame}

\begin{frame}{Блок Guesser}
\framesubtitle{Архитектура}
    \begin{columns}
    
    \column{0.6\textwidth}
    \begin{figure}[bht]
    \includegraphics[width=.9\textwidth]{guesser.png}
    % \caption{Архитектура блока Guesser}
    \end{figure}

    \column{0.4\textwidth}
    Входные данные:
    \begin{itemize}
        \item эмбеддинги дикторов\\
            $G = [g_1; g_2; \ldots g_K]$
        \item эмбеддинги слов\\
            $X = [x_1; x_2; \ldots x_T]$
    \end{itemize}
    Выходные данные:
    \begin{itemize}
        \item вероятности
            $\{P(g_i = g^*) \;|\; i=1..K\}$
    \end{itemize}
    
    \end{columns}

    \begin{block}{Обозначения}
    \begin{tabular}{l l}
        $K$ & количество гостей / дикторов\\
        $T$ & количество запрашиваемых слов
    \end{tabular}
    \end{block}
\end{frame}

\begin{frame}[fragile]{Блок Guesser}
\framesubtitle{Псевдокод 1 итерации обучения}
\begin{verbatim}
speaker_ids = speakers.sample(size=K)
G = voice_prints.get(speaker_ids)
target = randrange(0, K)
word_inds = randrange(0, V, size=T)
X = word_vocab.get(speaker=speaker_ids[target],
                   words=word_inds)
prediction = guesser.forward(G, X)
loss = cross_entropy(prediction, target)
\end{verbatim}
    \begin{block}{Обозначения}
    \begin{tabular}{l l}
        $K$ & количество гостей / дикторов\\
        $T$ & количество запрашиваемых слов\\
        $V$ & размер словаря --- число доступных для запроса слов
    \end{tabular}
    \end{block}
\end{frame}

\begin{frame}{Блок Enquirer}
\framesubtitle{Архитектура}
    \begin{columns}
    
    \column{0.6\textwidth}
    \begin{figure}[bht]
    \includegraphics[width=.9\textwidth]{enquirer.png}
    % \caption{Архитектура блока Enquirer}
    \end{figure}

    \column{0.4\textwidth}
    Входные данные:
    \begin{itemize}
        \item среднее эмб. дикторов\\
            $\hat{g} = \frac{1}{K}{\sum_{i=1}^{K}{g_k}}$
        \item эмбеддинги слов\\
            $X = [x_1; x_2; \ldots; x_t]$
    \end{itemize}
    Выходные данные:
    \begin{itemize}
        \item вероятность выбрать каждое из слов
    \end{itemize}

    \end{columns}

    \begin{block}{Обозначения}
    \begin{tabular}{l l}
        $K$ & количество гостей / дикторов\\
        $T$ & количество запрашиваемых слов\\
        $t$ & количество запрошенных слов, $0 \leq t \leq T$
    \end{tabular}
    \end{block}
\end{frame}

\begin{frame}[fragile]{Блок Enquirer}
\framesubtitle{Псевдокод 1 эпизода ISR-игры}
\footnotesize
\begin{verbatim}
speaker_ids = speakers.sample(size=K)
G = voice_prints.get(speaker_ids)
target = randrange(0, K)

g_hat = G.mean(dim=0)
x_i = start_tensor
X = []
for i in range(T):
    probs = enquirer.forward(g_hat, x_i)
    if training:
        distribution = multinomial(probs)
        word_ind = distribution.sample()
    else:
        word_ind = argmax(probs)
    x_i = word_vocab.get(speaker=speaker_ids[target], word=word_ind)
    X.append(x_i)

prediction = guesser.predict(G, X)
reward = 1 if prediction == target else 0
\end{verbatim}
\end{frame}

\begin{frame}{Входные данные}
    Для обучения использовался датасет \textbf{TIMIT}:
    \begin{itemize}
        \item 630 дикторов из США, 8 акцентов;
        \item каждый диктор произносит 10 предложений: 8 уникальных и 2 общих.
    \end{itemize}

    В качестве эмбеддингов использовались \textbf{x-vectors}, полученные с помощью нейронной сети, обученной на аугментированных датасетах для распознавания диктора \textit{Switchboard}, \textit{Mixer 6} и \textit{NIST}.
    \begin{itemize}
        \item Эмбеддинги дикторов $g$ получались с помощью усреднения
        эмбеддингов 8 уникальных предложений.
        \item Эмбеддинги слов $x$ извлекались с помощью 2 общих предложений,
        т.е. сначала вырезались записи одиночных слов, которые затем
        пропускались через нейронную сеть.
    \end{itemize}
\end{frame}

\begin{frame}{Результаты из статьи}
    \begin{figure}[htb]
    \only<1>{\includegraphics[scale=0.5]{isr_training.png}}
    \only<2>{\includegraphics[scale=0.5]{isr_word_sweep.png}}
    \end{figure}

    \begin{itemize}
        \item <1->  RL-агент при выборе запрашиваемых слов учитывает контекст ---
        он опережает не только случайного агента, но и эвристического,
        выбирающего из подмножества ``лучших'' слов.
        \item <2-> Преимущество RL-агента невелико и проявляется только при
        небольшом числе запрашиваемых слов.
    \end{itemize}
\end{frame}

\begin{frame}{Извлечение эмбеддингов}
\begin{block}{Цитата из статьи}
    We use MFCCs of dimension 20 with a frame-length of 25ms, mean-normalized
    over a sliding window of three seconds. We then process the MFCCs features
    through a pretrained X-Vector network to obtain a high quality voice
    embedding of fixed dimension 128 [\ldots].
    \end{block}

    \begin{itemize}
        \item У данной нейросети есть только 512-мерные выходы.
        \item При обучении нейросети в \texttt{kaldi} выходы нейросети
              подвергаются обработке --- вычитается среднее по всем дикторам и
              понижается размерность с помощью LDA\@.
        \item Мои попытки выполнять подобную постообработку с помощью
              \texttt{sklearn} / \texttt{numpy} заканчивались неудачей --- при
              обучении \texttt{guesser} отсутствовала генерализация.
        \item \textbf{Итог}: я использовал 512-мерные эмбеддинги, получаемые
        напрямую с выходов нейросети.
    \end{itemize}
\end{frame}

\begin{frame}{Обучение Guesser --- первые результаты}
    \framesubtitle{$K = 5$ дикторов и $T = 3$ слова}
    \begin{figure}
        \centering
        \includegraphics[scale=0.4]{guesser_training_v1.png}
        % \caption{Обучение guesser -- первые результаты}
    \end{figure}

    Увеличение размерности эмбеддингов $d$ со 128 до 512 позволило существенно улучшить точность ($\sim$80\% вместо 74.1\% в оригинальной статье).
\end{frame}

\begin{frame}{Обучение Enquirer --- первые результаты}
    \framesubtitle{$K = 5$ дикторов и $T = 3$ слова}
    \begin{figure}
        \centering
        \includegraphics[scale=0.4]{enquirer_training_v1.png}
        % \caption{Обучение enquirer -- первые результаты}
    \end{figure}
    \begin{itemize}
        \item Точность ниже, чем в статье (88.6\%), но явно есть возможность её
        улучшить.
        \item Обучение с помощью PPO, награда $R=1$ выдается в том случае, когда
        в конце эпизода guesser правильно угадывает диктора.
    \end{itemize}
\end{frame}

\begin{frame}{Обучение Guesser --- подбор гиперпараметров}
    \framesubtitle{$K = 5$ дикторов и $T = 3$ слова}
    Средняя награда (точность) на валидационной выборке:
    \begin{figure}
        \centering
        \includegraphics[width=.7\textwidth]{guesser_hpo.png}
        % \caption{Оптимизация LR и размера батча}
    \end{figure}
    \begin{itemize}
        \item Такая же точность достигается и на тестовой выборке.
        \item Обучение enquirer позволяет увеличить точность до 96\%.
    \end{itemize}
\end{frame}

\begin{frame}{Дальнейшие планы}
    \begin{itemize}
        \item Оптимизация гиперпараметров и доработка enquirer.
        \item Реализация эвристических агентов и сравнение их с нейросетевой
              моделью.
        \item Проведение экспериментов в более тяжёлых режимах (больше дикторов,
              меньше слов).
        \item Использование других эмбеддингов.
        \item Исследование робастности модели.
        \item Эксперименты с архитектурой enquirer / guesser.
    \end{itemize}
\end{frame}

\end{document}
