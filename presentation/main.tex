\documentclass[aspectratio=169]{beamer}
\usetheme{Boadilla}
\setbeamertemplate{navigation symbols}{}
\usepackage{graphicx} % Required for inserting images
\graphicspath{{./figures}}
\usepackage[autostyle=true]{csquotes}
\usepackage[T2A]{fontenc}
\usepackage[english, russian]{babel}

\title{Interactive Speaker Recognition}
\subtitle{Применение обучения с подкреплением для решения задачи распознавания
          диктора}
\author[В.С.~Головин]{Вячеслав Головин \texorpdfstring{\newline}{, }
    {\small Евгений Шуранов (руководитель)}}
\institute[ВШЭ]{Huawei CBG AI и ФКН ВШЭ СПб}
\date{10.05.2023}

\newcommand{\guesser}{\texttt{Guesser}}
\newcommand{\enquirer}{\texttt{Enquirer}}

\begin{document}

\frame{\titlepage}

\begin{frame}{}
    \textbf{Задача:} повышение точности систем верификации / идентификации
    диктора. Такая система может, например, быть использована для подтверждение
    личности на мобильных устройствах.\vspace{1em}

    \textbf{Требования к системе:}
    \begin{itemize}
        \item короткие запросы (не раздражаем пользователя),
        \item разнообразные запросы (не боимся спуфинга),
        \item высокая точность (без комментариев).
    \end{itemize}\vspace{1em}

    \textbf{Предлагаемое решение:} использование RL-агента для выбора
    запрашиваемых слов.\vspace{1em}

    \textbf{Новизна дипломной работы:}
    \begin{itemize}
        \item переход от идентификации к верификации,
        \item более гибкая система для выбора слов.
    \end{itemize}
\end{frame}

\begin{frame}{Interactive Speaker Recognition}
    Метод был предложен в статье \textit{A Machine of Few Words --- Interactive
    Speaker Recognition with Reinforcement Learning}, Mathieu Seurin et al.,
    INTERSPEECH 2020, arXiv:2008.03127v1.\vspace{1em}

    \begin{columns}
    
    \column{0.6\textwidth}
    \begin{figure}[bht]
        \includegraphics[width=.9\textwidth]{isr_game_large.png}
        % \caption{Общая схема подхода ISR}
    \end{figure}

    \column{0.4\textwidth}
    Важные особенности:
    \begin{enumerate}
        \item Рассматривается только задача идентификации.
        \item Набор слов строго фиксирован.
        \item Разные нейронные сети для двух задач SR Module --- запроса слов
        (\enquirer) и идентификации диктора (\guesser).
    \end{enumerate}
    \end{columns}
\end{frame}

\begin{frame}{Блок Guesser}
\framesubtitle{Архитектура}
    \begin{columns}
    
    \column{0.6\textwidth}
    \begin{figure}[bht]
    \includegraphics[width=.8\textwidth]{guesser.png}
    % \caption{Архитектура блока Guesser}
    \end{figure}

    \column{0.4\textwidth}
    Входные данные:
    \begin{itemize}
        \item эмбеддинги дикторов\\
            $G = [g_1; g_2; \ldots g_K]$
        \item эмбеддинги слов\\
            $X = [x_1; x_2; \ldots x_T]$
    \end{itemize}
    Выходные данные:
    \begin{itemize}
        \item вероятности
            $\{P(g_i = g^*) \;|\; i=1..K\}$
    \end{itemize}
    \end{columns}

    \begin{block}{Обозначения}
    \begin{tabular}{l l}
        $K$ & количество гостей / дикторов\\
        $T$ & количество запрашиваемых слов
    \end{tabular}
    \end{block}
\end{frame}

\begin{frame}[fragile]{Блок Guesser}
\framesubtitle{Псевдокод 1 итерации обучения}
\input{guesser_forward.tex}
    \begin{block}{Обозначения}
    \begin{tabular}{l l}
        $K$ & количество гостей / дикторов\\
        $T$ & количество запрашиваемых слов\\
        $V$ & размер словаря --- число доступных для запроса слов
    \end{tabular}
    \end{block}
\end{frame}

\begin{frame}{Блок Enquirer}
\framesubtitle{Архитектура}
    \begin{columns}
    
    \column{0.6\textwidth}
    \begin{figure}[bht]
    \includegraphics[width=.9\textwidth]{enquirer.png}
    % \caption{Архитектура блока Enquirer}
    \end{figure}

    \column{0.4\textwidth}
    Входные данные:
    \begin{itemize}
        \item среднее эмб. дикторов\\
            $\hat{g} = \frac{1}{K}{\sum_{i=1}^{K}{g_k}}$
        \item эмбеддинги слов\\
            $X = [x_1; x_2; \ldots; x_t]$
    \end{itemize}
    Выходные данные:
    \begin{itemize}
        \item вероятность выбрать каждое из слов
    \end{itemize}

    \end{columns}

    \begin{block}{Обозначения}
    \begin{tabular}{l l}
        $K$ & количество гостей / дикторов\\
        $T$ & количество запрашиваемых слов\\
        $t$ & количество запрошенных слов, $0 \leq t \leq T$
    \end{tabular}
    \end{block}
\end{frame}

\begin{frame}[fragile]{Блок Enquirer}
\framesubtitle{Псевдокод 1 эпизода ISR-игры}
\footnotesize
\input{enquirer_forward.tex}
\end{frame}

\begin{frame}{Входные данные}
    Для обучения использовался датасет \textbf{TIMIT}:
    \begin{itemize}
        \item 630 дикторов из США, 8 акцентов;
        \item каждый диктор произносит 10 предложений: 8 уникальных и 2 общих.
    \end{itemize}

    В качестве эмбеддингов использовались \textbf{x-vectors}, полученные с помощью нейронной сети, обученной на аугментированных датасетах для распознавания диктора \textit{Switchboard}, \textit{Mixer 6} и \textit{NIST}.
    \begin{itemize}
        \item Эмбеддинги дикторов $g$ получались с помощью усреднения
        эмбеддингов 8 уникальных предложений.
        \item Эмбеддинги слов $x$ извлекались с помощью 2 общих предложений,
        т.е. сначала вырезались записи одиночных слов, которые затем
        пропускались через нейронную сеть.
    \end{itemize}
\end{frame}

\begin{frame}{Результаты из статьи}
    \framesubtitle{$K = 5$ дикторов и $T = 3$ слова}
    \begin{figure}[htb]
    \only<1>{\includegraphics[scale=0.5]{isr_training.png}}
    \only<2>{\includegraphics[scale=0.5]{isr_word_sweep.png}}
    \end{figure}

    \begin{itemize}
        \item <1->  RL-агент при выборе запрашиваемых слов учитывает контекст ---
        он опережает не только случайного агента, но и эвристического,
        выбирающего из подмножества ``лучших'' слов.
        \item <2-> Преимущество RL-агента невелико и проявляется только при
        небольшом числе запрашиваемых слов.
    \end{itemize}
\end{frame}

\begin{frame}{Воспроизведение результатов}
    Основная возникшая проблема --- размерность эмбеддингов. В статье
    используются 128-мерные эмбеддинги, в то время как использованная для их
    извлечения нейросеть имеет только 512-мерные выходы.

    Информации о способе понижения размерности в статье нет. При этом
\end{frame}

\begin{frame}{Извлечение эмбеддингов}
\begin{block}{Цитата из статьи}
    We use MFCCs of dimension 20 with a frame-length of 25ms, mean-normalized
    over a sliding window of three seconds. We then process the MFCCs features
    through a pretrained X-Vector network to obtain a high quality voice
    embedding of fixed dimension 128 [\ldots].
    \end{block}

    \begin{itemize}
        \item У данной нейросети есть только 512-мерные выходы.
        \item При обучении нейросети в \texttt{kaldi} выходы нейросети
              подвергаются обработке --- вычитается среднее по всем дикторам и
              понижается размерность с помощью LDA\@.
        \item Мои попытки выполнять подобную постообработку с помощью
              \texttt{sklearn} / \texttt{numpy} заканчивались неудачей --- при
              обучении \texttt{guesser} отсутствовала генерализация.
        \item \textbf{Итог}: я использовал 512-мерные эмбеддинги, получаемые
        напрямую с выходов нейросети.
    \end{itemize}
\end{frame}

\begin{frame}{Обучение Guesser --- первые результаты}
    \framesubtitle{$K = 5$ дикторов и $T = 3$ слова}
    \begin{figure}
        \centering
        \includegraphics[scale=0.4]{guesser_training_v1.png}
        % \caption{Обучение guesser -- первые результаты}
    \end{figure}

    Увеличение размерности эмбеддингов $d$ со 128 до 512 позволило существенно улучшить точность ($\sim$80\% вместо 74.1\% в оригинальной статье).
\end{frame}

\begin{frame}{Обучение Enquirer --- первые результаты}
    \framesubtitle{$K = 5$ дикторов и $T = 3$ слова}
    \begin{figure}
        \centering
        \includegraphics[scale=0.4]{enquirer_training_v1.png}
        % \caption{Обучение enquirer -- первые результаты}
    \end{figure}
    \begin{itemize}
        \item Точность ниже, чем в статье (88.6\%), но явно есть возможность её
        улучшить.
        \item Обучение с помощью PPO, награда $R=1$ выдается в том случае, когда
        в конце эпизода guesser правильно угадывает диктора.
    \end{itemize}
\end{frame}

\begin{frame}{Обучение Guesser --- подбор гиперпараметров}
    \framesubtitle{$K = 5$ дикторов и $T = 3$ слова}
    Средняя награда (точность) на валидационной выборке:
    \begin{figure}
        \centering
        \includegraphics[width=.7\textwidth]{guesser_hpo.png}
        % \caption{Оптимизация LR и размера батча}
    \end{figure}
    \begin{itemize}
        \item Такая же точность достигается и на тестовой выборке.
        \item Обучение enquirer позволяет увеличить точность до 96\%.
    \end{itemize}
\end{frame}

\begin{frame}{Дальнейшие планы}
    \begin{itemize}
        \item Оптимизация гиперпараметров и доработка enquirer.
        \item Реализация эвристических агентов и сравнение их с нейросетевой
              моделью.
        \item Проведение экспериментов в более тяжёлых режимах (больше дикторов,
              меньше слов).
        \item Использование других эмбеддингов.
        \item Исследование робастности модели.
        \item Эксперименты с архитектурой enquirer / guesser.
    \end{itemize}
\end{frame}

\end{document}
