\subsection{От идентификации к верификации}

В первых двух главах этого отчёта мы изучали предложенную в~\citeisr{} систему
распознавания диктора. С нашей точки зрения у неё есть серьёзный недостаток ---
она решает задачу \emph{идентификации}, в то время как интересная нам с
практической точки зрения система аутентификации пользователя должна решать
задачу \emph{верификации}. Ранее мы сформулировали \hl{(правда?)} тезис о том,
что это не является большой проблемой, и переход идентификация--верификация
можно выполнить без особых проблем. Обсуждению этого вопроса посвящён данный
раздел.

Сначала проговорим, как меняется наша задача. Ранее мы должны были выбрать
одного из $K$ дикторов произнесшего $T$ слов, т.~е. мы использовали $K$
эмбеддингов дикторов и $T$ эмбеддингов слов. В случае верификации у нас есть
только 1 диктор, от нас требуется ответить на вопрос, является ли он человеком,
произнесшим услышанную нами речь. Подумаем, какие изменения нам нужно внести
в архитектуру использованных нами нейросетей.

В случае \enquirer{} (нейросети для выбора запрашиваемых слов) ответ оказывается
предельно простым --- нам не нужны никакие изменения. Действительно, сами
эмбеддинги диктора на вход этой модели не поступают, используется только их
среднее $\hat{g}$, которое в случае верификации будет просто равно эмбеддингу
единственного диктора.

\begin{table}[htb]
    \centering
    \begin{tabular}{c c c}
        \toprule
        Выбор слов & Режим обучения & Точность\\
        \midrule
        случайный & \multirow{3}{4em}{$T = 3$} & 0.895 \\
        \enquirer{} & & 0.933\\
        эвристика & & 0.917\\
        \midrule
        случайный & \multirow{3}{4em}{$T = 2$} & 0.913 \\
        \enquirer{} & & 0.947\\
        эвристика & & 0.945\\
        \bottomrule
    \end{tabular}
    \caption{Точность верификации, $T = 3$ запрашиваемых слова}
    \label{tab:ver}
\end{table}

Ситуация с \guesser{} лишь немного сложнее. Т.~к. его архитектура позволяет
рассматривать игры с произвольным числом дикторов, проблемы возникают только на
самом последнем слое, выполняющим операцию \texttt{softmax}. На данном этапе у
модели (для каждой игры) есть только одно число, которое фактические является
некоторой метрикой соответствия между взвешенной суммой эмбеддингов слов
$\hat{x}$ и эмбеддингом диктора $g$. В таком случае для принятия решения о
(не-)соответствии речи и диктора логично применить операцию \texttt{sigmoid}
(логистическую функцию), превращающее эту метрику в число от $0$ до $1$.

Действительно, такое простое преобразование позволяет получить работающую
систему верификации диктора. Полученные результаты приведены в
табл.~\ref{tab:ver}. Как и в случае идентификации, обучение в более тяжелом
режиме (здесь мы можем только сокращать число запрашиваемых слов) позволяет
немного улучшить результаты, но при этом преимущество перед простым эвристическим
агентом\footnote{
    Здесь он, как и ранее, просто всегда выбирает одни и те же слова,
    соответствующие наибольшой средней точности на валидационной выборке.
    Переход к верификации практически никак не меняет градацию слов.
} тоже является минимальным.

\subsection{\cbenquirer{} --- гибкая система выбора слов}

Перейдём к обсуждению другой проблемы реализованной нами модели --- наличия
фиксированного списка слов. Действительно, в качестве одного из преимуществ
разрабатываемой системы мы ранее \hl{(не)} называли возможность делать
разнообразные запросы. Однако используемый до данного момента времени вариант
\enquirer{} слабо соответствует этому требованию --- он осуществляет выбор из
20 слов. Конечно, этот список может быть и больше, для этого просто потребуется
больший объём данных для обучения. Но при добавлении любого слова потребуется
либо заново обучать \enquirer{}, либо выполнять fine-tuning, что выглядит не
самым оптимальным вариантом для готового продукта.

Для решения этой проблемы была разработана архитектура \cbenquirer{}. Она
представляет собой простую модификацию оригинальной модели:
\begin{enumerate}
    \item ``Голова'' модели представляет собой \enquirer{}, в котором число
    выходов равно размерности эмбеддингов, и к ним не применяется операция
    \texttt{softmax}. Таким нехитрым способом мы преобразовали выходы модели из
    вероятностного распределения по словарю в эмбеддинг запрашиваемого слова.
    \item Естественно, стоящая перед \cbenquirer{} задача никак не поменялась ---
    у нас все ещё существует некоторый конечный набор слов, из которых на
    каждом шаге игры нам нужно выбрать одно (или, что лучше, получить
    распределение). Для этого мы составляем \texttt{Codebook} --- тензор из
    эмбеддингов слов, которые рассчитываются как среднее по всем дикторам из
    обучающей выборки.
    \item Наконец, нам нужно как-то сопоставить возвращаемый моделью эмбеддинг
    с эмбеддингами из \texttt{Codebook}. Самый очевидный вариант --- просто
    найти ближайший по $L_2$-норме. Примерно это мы и делаем, вероятность
    выбрать $i$-ое слово из \texttt{Codebook} вычисляется по формуле:
    \begin{equation*}
        p_i = \frac{\exp{(-d_i/T)}}{\sum_{j=0}^{V}{\exp{(-d_j/T)}}},
    \end{equation*}
    где $d_i$ --- расстояние\footnote{
        Для численной стабильности мы используем среднеквадратичную ошибку (MSE)
        вместо $L_2$-нормы.
    } между выходным эмбеддингом и $i$-ым вектором из \texttt{Codebook}, $T$ ---
    обучаемый параметр модели, $V$ --- размер словаря.
\end{enumerate}

В наших экспериментах такая модификация показала результаты, сравнимые с
оригинальной версией \enquirer{} \hl{[привести результаты]}. Далее мы решили
проверить, возможно ли изменение набора слов без дообучения модели. Для этого
мы обучили \cbenquirer{} на половине словаря и протестировали его на другой
половине. В таком случае мы наблюдали лишь небольшое падение точности, которое,
скорее всего, просто объясняется уменьшением размера используемого словаря.

\subsection{Добавление шума}

Следующим экспериментом была проверка того, будет ли работать предложенный
подход при наличии фонового шума. Для этого мы выбрали 6~аудиозаписей шума
из датасета MUSAN\cite{musan2015} и добавили их случайные фрагменты\footnote{
    Аудиозаписи специально выбирались таким образом, чтобы их случайные
    короткие фрагменты отличались слабо.
} к аудиозаписям слов. Соотношение сигнал~/~шум было выбрано равным 3~дБ.
При обучении и тестировании моделей тип шума выбирался случайно, но он не
менялся в течение игры.

\begin{table}[htb]
    \begin{tabular}{c c c}
        \toprule
        Модель & Идентификация & Верификация\\
        \midrule
        \guesser{} & 0.887 & 0.895\\
        \guesser{} + \enquirer{} & 0.946 & 0.934\\
        \guesser{} + эвристика (3 лучших) & 0.957 & 0.938\\
        \bottomrule
    \end{tabular}
    \caption{Точность идентификации и верификации в стандартных режимах
    ($T = 3$ слова, $K = 5$ гостей при идентификации) при добавлении фонового
    шума.}
    \label{tab:noise}
\end{table}

Полученные результаты приведены в табл.~\ref{tab:noise}. Видно, что добавление
шума сделало задачу тяжелее, из-за чего точность SR-систем немного упала. Также
любопытно, что простой эвристический агент снова не проиграл \enquirer{}.
Причина этого стала понятна после измерения средней точности \guesser{} на
аудиозаписях зашумлённых слов: выяснилось, что хотя добавление того или иного
типа шума влияет на градацию слов (которую использует эвристический агент),
этот эффект невелик. Иными словами, ``хорошие'' слова, с помощью которых в
среднем достигается самая высокая точность распознавания диктора, остались
такими же и при добавлении различных типов фонового шума.

\subsection{Альтернативные эмбеддинги}\label{ssec:cpc}

Во всех описанных ранее экспериментах для получения эмбеддингов мы использовали
\xvector{}\cite{xvectorspaper}. Здесь мы, как и во многих других моментах,
повторяем подход авторов оригинальной статьи. Проблема в том, что выбор таких
старых (2017~год) эмбеддингов выглядел немного странным уже на момент написания
оригинальной статьи (2020~год). Сегодня же они выглядят безнадёжно устаревшими.

Поэтому для последнего эксперимента мы проверили, как разработанная SR-модель
работает с другими эмбеддингами. Для этого использовалась нейросеть, обученная
нашими коллегами из лаборатории Huawei CBG AI на 960~часах аудиозаписей из
датасета LibriSpeech\cite{librispeech} и использующая метод контрастного прогнозирующего
кодирования\cite{oord2019representation}.

\hl{результаты}
