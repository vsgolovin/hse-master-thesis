\subsection{От идентификации к верификации}

В первых двух главах этого отчёта мы изучали предложенную в~\citeisr{} систему
распознавания диктора. С нашей точки зрения у неё есть серьёзный недостаток ---
она решает задачу \emph{идентификации}, в то время как интересная нам с
практической точки зрения система аутентификации пользователя должна решать
задачу \emph{верификации}. Ранее мы сформулировали \hl{(правда?)} тезис о том,
что это не является большой проблемой, и переход идентификация--верификация
можно выполнить без особых проблем. Обсуждению этого вопроса посвящён данный
раздел.

Сначала проговорим, как меняется наша задача. Ранее мы должны были выбрать
одного из $K$ дикторов произнесшего $T$ слов, т.~е. мы использовали $K$
эмбеддингов дикторов и $T$ эмбеддингов слов. В случае верификации у нас есть
только 1 диктор, от нас требуется ответить на вопрос, является ли он человеком,
произнесшим услышанную нами речь. Подумаем, какие изменения нам нужно внести
в архитектуру использованных нами нейросетей.

В случае \enquirer{} (нейросети для выбора запрашиваемых слов) ответ оказывается
предельно простым --- нам не нужны никакие изменения. Действительно, сами
эмбеддинги диктора на вход этой модели не поступают, используется только их
среднее $\hat{g}$, которое в случае верификации будет просто равно эмбеддингу
единственного диктора.

\begin{table}[htb]
    \centering
    \begin{tabular}{c c c}
        \toprule
        Выбор слов & Режим обучения & Точность\\
        \midrule
        случайный & \multirow{3}{4em}{$T = 3$} & 0.895 \\
        \enquirer{} & & 0.933\\
        эвристика & & 0.917\\
        \midrule
        случайный & \multirow{3}{4em}{$T = 2$} & 0.913 \\
        \enquirer{} & & 0.947\\
        эвристика & & 0.945\\
        \bottomrule
    \end{tabular}
    \caption{Точность верификации, $T = 3$ запрашиваемых слова}
    \label{tab:ver}
\end{table}

Ситуация с \guesser{} лишь немного сложнее. Т.~к. его архитектура позволяет
рассматривать игры с произвольным числом дикторов, проблемы возникают только на
самом последнем слое, выполняющим операцию \texttt{softmax}. На данном этапе у
модели (для каждой игры) есть только одно число, которое фактические является
некоторой метрикой соответствия между взвешенной суммой эмбеддингов слов $\hat{x}$
и эмбеддингом диктора $g$. В таком случае для принятия решения о (не-)соответствии
речи и диктора логично применить операцию \texttt{sigmoid} (логистическую функцию),
превращающее эту метрику в число от $0$ до $1$.

Действительно, такое простое преобразование позволяет получить работающую
систему верификации диктора. Полученные результаты приведены в
табл.~\ref{tab:ver}. Как и в случае идентификации, обучение в более тяжелом
режиме (здесь мы можем только сокращать число запрашиваемых слов) позволяет
немного улучшить результаты, но при этом преимущество перед простым эвристическим
агентом\footnote{
    Здесь он, как и ранее, просто всегда выбирает одни и те же слова,
    соответствующие наибольшой средней точности на валидационной выборке.
    Переход к верификации практически никак не меняет градацию слов.
} тоже является минимальным.

\subsection{\cbenquirer{} --- гибкая система выбора слов}

Перейдём к обсуждению другой проблемы реализованной нами модели --- наличие
фиксированного списка слов.

\subsection{Добавление шума}
обучается норм, результаты такие же

\subsection{Альтернативные эмбеддинги}\label{ssec:cpc}
внезапно эмбеддинги 2017 года оказались не очень
