\subsection{Данные для обучения и извлечение эмбеддингов}

Здесь мы практически полностью повторяем описанный в~\cite{isrpaper} подход.
Единственным (но очень существенным) отличием является использованная размерность
эмбеддингов. Перед тем как перейти к обсуждению этого момента, расскажем про
исходные данные.

Итак, для обучения и тестирования моделей мы использовали датасет
TIMIT\cite{timit}. Он составлен из аудиозаписей речи 630~дикторов, говорящих на
8~основных диалектах американского английского языка. Эти дикторы поделены на
обучающую (\texttt{train}) и тестовую (\texttt{test}) выборки, в первую входят
468~дикторов, во вторую --- 162. Для обучения нейросетевых моделей мы также
создавали валидационную выборку, в которую выделялись 20\% дикторов из обучающей.

Каждый из дикторов произносит 10~фонетически насыщенных предложений. При этом 2
из 10 предложений являются общими для всех дикторов
\footnote{Общие предложения:\\
          \textit{She had your dark suit in greasy wash water all year.}\\
          \textit{Don't ask me to carry an oily rag like that.}}
, остальные 8 уникальны для каждого диктора. Такое разделение позволяет без
особых затруднений подготовить данные, необходимые для описанной
в~\ref{ssec:isr} игры:
\begin{itemize}
    \item 2~общих предложения можно использовать для получения аудиозаписей
    слов.  Для этого разделим аудиозаписи этих предложений по временным
    отметкам, предоставленным создателями датасета. В результате получим 20
    аудиозаписей слов\footnote{Аналогично~\cite{isrpaper} мы не используем слово
    \textit{an}.} для каждого диктора.
    \item 8~уникальных для каждого диктора предложений можно использовать для
    получения голосовых подписей --- эмбеддингов дикторов --- просто при помощи
    усреднения эмбеддингов аудиозаписей этих предложений.
\end{itemize}

В качестве векторов признаков использовались эмбеддинги
\xvector{}~\cite{xvectorspaper}. Весь процесс преобразования аудиозаписей в
векторы признаков осуществлялся с помощью библиотеки Kaldi~\cite{kaldi}. На
первом этапе рассчитывалиcь мел-частотные кепстральные коэффициенты\footnote{
Параметры аналогичны использованным в~\cite{isrpaper} и определяются
требованиями предобученной модели.} и производилось детектирование голосовой
активности (\textit{aнгл.} VAD --- voice activity detection). Полученные векторы
признаков поступали на вход предобученной нейронной сети~\cite{sre16model}. В
качестве эмбеддингов использовались данные со второго 512-мерного слоя.

Здесь, как уже было сказано ранее, мы отступаем от оригинальной
работы~\cite{isrpaper}, где использовались 128-мерные эмбеддинги. На это есть
две причины. Во-первых, из приведенных в~\cite{isrpaper} комментариев
неочевидно\footnote{
    Цитата: \textit{We then process the MFCCs features through a pretrained
    X-Vector network to obtain a high quality voice embedding of fixed dimension
    128, where the X-Vector network is trained on augmented Switchboard, Mixer~6
    and NIST SREs}.
}, как производилось понижение размерности.
Во-вторых, мотивация такого преобразования тоже неочевидна. Уже первые проведенные
нами эксперименты показали, что при использовании 512-мерных эмбеддингов точность
идентификации оказывается существенно выше приведенных в~\cite{isrpaper} значений.

\subsection{Обучение \guesser{}}

Первой обучается нейронная сеть \guesser{}, выполняющая выбор из $K$ дикторов
при помощи $T$ аудиозаписей произнесенных слов. Как уже было сказано ранее,
эта нейросеть тренируется в режиме обучения с учителем, дикторы и произносимые
слова выбираются случайно, в качестве функции используется кросс-энтропия.
Процесс вычисления значения функции потерь для одной игры можно записать
следующим образом:
\input{guesser_forward.tex}

Из-за увеличения относительно \citeisr{} размерности эмбеддингов пропорционально
увеличились и размерности слоёв \guesser{}. Из-за этого нам пришлось изменить
гиперпараметры, в частности мы сильно уменьшили темп обучения
(\textit{learning rate}).

Как и в оригинальной статье, для сравнения моделей будем строить графики
\textit{word} и \textit{guest sweep}. Т.~е. будем обучать модель в режиме с $K =
5$ дикторами и $T = 3$ запрашиваемыми словами, а затем будем тестировать её в
режимах с отличным числом дикторов или слов. Здесь и далее, если это не оговорено
отдельно, для расчёта точности проводятся $20000$ игр среди дикторов из тестовой
выборки, эксперименты повторяются по 5~раз c различным \texttt{seed} генератора
случайных чисел.

\begin{figure}[htb]
    \centering
    \includegraphics[scale=1.0]{../plots/guest_sweep.pdf}
    \caption{Зависимость точности \guesser{} обученного нами и авторами
    \citeisr{} от числа дикторов $K$. Модели обучены в режиме $K = 5$, $T = 3$.}
\end{figure}

\begin{figure}[htb]
    \centering
    \includegraphics[scale=1.0]{../plots/word_sweep.pdf}
    \caption{Зависимость точности \guesser{} обученного нами и авторами
    \citeisr{} от числа запрошенных слов $T$. Модели обучены в режиме $K = 5$,
    $T = 3$.}
\end{figure}

По приведенным на графиках результатам видно, что увеличение размерности
эмбеддингов существенно улучшает точность идентификации, разница особо
велика в режимах с большим числом дикторов $K$.

\subsection{Обучение \enquirer{}}

Для обучения \enquirer{} --- модели выбора слов --- уже нужна обученная модель
\guesser{}. На этом этапе уже используется обучение с подкреплением, псевдокод
для 1~игры приведён ниже.
\input{enquirer_forward.tex}

Как видно из приведенного псевдокода, награда выдается в том случае, когда
\guesser{} правильно угадывает диктора. Для обучения мы использовали алгоритм
PPO~\cite{schulman2017proximal} --- здесь мы снова повторяем подход
авторов~\citeisr{}. В целом выбор метода выглядит разумным --- PPO
зарекомендовал себя как простой и универсальный алгоритм, позволяющий достигать
хороших результатов. Однако некоторые особенности нашей задачи --- дискретное
пространство действий, малая длительность эпизодов --- выглядят лучше подходящими
для off-policy алгоритмов. К сожалению, у нас не нашлось времени, чтобы проверить
эту гипотезу.

\begin{figure}[htb]
    \centering
    \includegraphics[scale=1.0]{../plots/guest_sweep_enq.pdf}
    \caption{Зависимость точности SR-систем с различными методами выбора слов
    --- нейросетевым агентов (\enquirer{}) и случайным (random agent) --- от
    числа дикторов $K$. Модели обучены в режиме $K = 5$, $T = 3$.}
\end{figure}

\begin{figure}[htb]
    \centering
    \includegraphics[scale=1.0]{../plots/word_sweep_enq.pdf}
    \caption{Зависимость точности SR-систем с различными методами выбора слов
    --- нейросетевым агентов (\enquirer{}) и случайным (random agent) --- от
    числа запрашиваемых слов $T$. Модели обучены в режиме $K = 5$, $T = 3$.}
\end{figure}

Приведенные результаты свидетельствуют о том, что \enquirer{} действительно
успешно обучается --- точность оказываются заметно выше, чем с случае
случайного выбора слов. Как и в случае повышения размерности эмбеддингов,
особенно большое различие наблюдается в режимах с большим числом дикторов.

\subsection{Эвристическая модель выбора слов}

\ldots