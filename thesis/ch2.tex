\subsection{Данные для обучения и извлечение эмбеддингов}

Здесь мы практически полностью повторяем описанный в~\cite{isrpaper} подход.
Единственным (но очень существенным) отличием является использованная размерность
эмбеддингов. Перед тем как перейти к обсуждению этого момента, расскажем про
исходные данные.

Итак, для обучения и тестирования моделей мы использовали датасет
TIMIT\cite{timit}. Он составлен из аудиозаписей речи 630~дикторов, говорящих на
8~основных диалектах американского английского языка. Эти дикторы поделены на
обучающую (\texttt{train}) и тестовую (\texttt{test}) выборки, в первую входят
468~дикторов, во вторую --- 162. Для обучения нейросетевых моделей мы также
создавали валидационную выборку, в которую выделялись 20\% дикторов из обучающей.

Каждый из дикторов произносит 10~фонетически насыщенных предложений. При этом 2
из 10 предложений являются общими для всех дикторов
\footnote{Общие предложения:\\
          \textit{She had your dark suit in greasy wash water all year.}\\
          \textit{Don't ask me to carry an oily rag like that.}}
, остальные 8 уникальны для каждого диктора. Такое разделение позволяет без
особых затруднений подготовить данные, необходимые для описанной
в~\ref{ssec:isr} игры:
\begin{itemize}
    \item 2~общих предложения можно использовать для получения аудиозаписей
    слов.  Для этого разделим аудиозаписи этих предложений по временным
    отметкам, предоставленным создателями датасета. В результате получим 20
    аудиозаписей слов\footnote{Аналогично~\cite{isrpaper} мы не используем слово
    \textit{an}.} для каждого диктора.
    \item 8~уникальных для каждого диктора предложений можно использовать для
    получения голосовых подписей --- эмбеддингов дикторов --- просто при помощи
    усреднения эмбеддингов аудиозаписей этих предложений.
\end{itemize}

В качестве векторов признаков использовались эмбеддинги
\xvector{}~\cite{xvectorspaper}. Весь процесс преобразования аудиозаписей в
векторы признаков осуществлялся с помощью библиотеки Kaldi~\cite{kaldi}. На
первом этапе рассчитывалиcь мел-частотные кепстральные коэффициенты\footnote{
Параметры аналогичны использованным в~\cite{isrpaper} и определяются
требованиями предобученной модели.} и производилось детектирование голосовой
активности (\textit{aнгл.} VAD --- voice activity detection). Полученные векторы
признаков поступали на вход предобученной нейронной сети~\cite{sre16model}. В
качестве эмбеддингов использовались данные со второго 512-мерного слоя.

Здесь, как уже было сказано ранее, мы отступаем от оригинальной работы
\cite{isrpaper}, где использовались 128-мерные эмбеддинги. На это есть две
причины. Во-первых, из приведенных в \cite{isrpaper} комментариев
неочевидно\footnote{
    Цитата: \textit{We then process the MFCCs features through a pretrained
    X-Vector network to obtain a high quality voice embedding of fixed dimension
    128, where the X-Vector network is trained on augmented Switchboard, Mixer~6
    and NIST SREs}.
}, как производилось понижение размерности.
Во-вторых, мотивация такого преобразования тоже неочевидна. Уже первые проведенные
нами эксперименты показали, что при использовании 512-мерных эмбеддингов точность
идентификации оказывается существенно выше приведенных в \cite{isrpaper} значений.

\subsection{Обучение \guesser{}}

\ldots

\subsection{Обучение \enquirer{}}

\ldots

\subsection{Эвристическая модель выбора слов}

\ldots